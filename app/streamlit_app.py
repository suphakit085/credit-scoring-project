import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt

# --- Constants ---
MODEL_PATH = 'models/best_model_lgbm.pkl'
FEATURE_NAMES_PATH = 'data/features/feature_names.csv'

# Helper to load features
@st.cache_data
def load_feature_names():
    if os.path.exists(FEATURE_NAMES_PATH):
        df = pd.read_csv(FEATURE_NAMES_PATH)
        return df['feature'].tolist()
    return []

EXPECTED_FEATURES = load_feature_names()

# Helper to load medians
@st.cache_data
def load_medians():
    path = 'data/processed/feature_medians.json'
    if os.path.exists(path):
        try:
            with open(path, 'r') as f:
                import json
                return json.load(f)
        except:
            return {}
    return {}

# --- Helper Functions ---
@st.cache_resource
def load_model():
    """Load the trained model and preprocessing artifacts from disk."""
    try:
        model = joblib.load(MODEL_PATH)
        # Load scaler and imputer if they exist (created by recreate_scaling.py)
        imputer = joblib.load('models/imputer.joblib')
        scaler = joblib.load('models/scaler.joblib')
        return model, imputer, scaler
    except FileNotFoundError as e:
        st.error(f"Error loading artifacts: {e}")
        return None, None, None
    except Exception as e:
        # Fallback for older sessions where artifacts might not be ready
        st.error(f"Unexpected error loading model: {e}")
        return None, None, None

# --- Main Logic ---
def main():
    st.title("üí≥ ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ (Credit Scoring)")
    st.markdown("""
    ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ** 
    ‡πÇ‡∏õ‡∏£‡∏î‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏Ç‡∏≠‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏¢‡∏ã‡πâ‡∏≤‡∏¢ (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏°‡∏ô‡∏π Sidebar) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    """)

    model, imputer, scaler = load_model()
    medians = load_medians()
    
    if model is None:
        st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `models/`")
        st.stop()

    # --- Sidebar Inputs ---
    st.sidebar.header("üìù ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏Ç‡∏≠‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠")

    # 1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
    st.sidebar.subheader("1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß")
    gender = st.sidebar.selectbox("‡πÄ‡∏û‡∏®", ["‡∏´‡∏ç‡∏¥‡∏á (Female)", "‡∏ä‡∏≤‡∏¢ (Male)"])
    age = st.sidebar.slider("‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏õ‡∏µ)", 20, 70, 30)
    education = st.sidebar.selectbox("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", 
                                     ["‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (Secondary)", "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ (Higher education)", "‡πÑ‡∏°‡πà‡∏à‡∏ö‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ (Incomplete higher)", "‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏ï‡πâ‡∏ô (Lower secondary)", "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ (Academic degree)"])
    family_status = st.sidebar.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß", 
                                         ["‡πÅ‡∏ï‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß (Married)", "‡πÇ‡∏™‡∏î (Single / not married)", "‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏™‡∏°‡∏£‡∏™ (Civil marriage)", "‡∏´‡∏°‡πâ‡∏≤‡∏¢ (Widow)", "‡∏´‡∏¢‡πà‡∏≤‡∏£‡πâ‡∏≤‡∏á/‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà (Separated)"])
    housing_type = st.sidebar.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏≠‡∏≤‡∏®‡∏±‡∏¢", 
                                        ["‡∏ö‡πâ‡∏≤‡∏ô/‡∏≠‡∏û‡∏≤‡∏£‡πå‡∏ó‡πÄ‡∏°‡∏ô‡∏ó‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß", "‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏û‡πà‡∏≠‡πÅ‡∏°‡πà", "‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏ó‡∏®‡∏ö‡∏≤‡∏•", "‡πÄ‡∏ä‡πà‡∏≤‡∏≠‡∏û‡∏≤‡∏£‡πå‡∏ó‡πÄ‡∏°‡∏ô‡∏ó‡πå", "‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡∏Å‡∏≤‡∏£", "‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏î/‡∏™‡∏´‡∏Å‡∏£‡∏ì‡πå"])

    # 2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô
    st.sidebar.subheader("2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô")
    income = st.sidebar.number_input("‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡πà‡∏≠‡∏õ‡∏µ (‡∏ö‡∏≤‡∏ó)", min_value=10000.0, value=50000.0, step=5000.0)
    credit_amount = st.sidebar.number_input("‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏Ç‡∏≠ (‡∏ö‡∏≤‡∏ó)", min_value=10000.0, value=200000.0, step=5000.0)
    annuity = st.sidebar.number_input("‡∏¢‡∏≠‡∏î‡∏ú‡πà‡∏≠‡∏ô‡∏ä‡∏≥‡∏£‡∏∞‡∏ï‡πà‡∏≠‡∏á‡∏ß‡∏î (‡∏ö‡∏≤‡∏ó)", min_value=1000.0, value=10000.0, step=500.0)
    goods_price = st.sidebar.number_input("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏Å‡∏£‡∏ì‡∏µ‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤) (‡∏ö‡∏≤‡∏ó)", min_value=10000.0, value=180000.0, step=5000.0)
    
    # 3. ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏™‡∏¥‡∏ô
    st.sidebar.subheader("3. ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏™‡∏¥‡∏ô")
    income_type = st.sidebar.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ",
                                       ["‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (Working)", "‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£/‡∏£‡∏±‡∏ê‡∏ß‡∏¥‡∏™‡∏≤‡∏´‡∏Å‡∏¥‡∏à (State servant)", "‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö‡∏ö‡∏≥‡∏ô‡∏≤‡∏ç (Pensioner)", "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏≠‡∏Å‡∏ä‡∏ô (Commercial associate)", "‡∏Ñ‡∏ô‡∏ß‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏ô/‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (Unemployed/Student)"])
    employment_years = st.sidebar.slider("‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (‡∏õ‡∏µ)", 0, 50, 5)
    occupation = st.sidebar.selectbox("‡∏≠‡∏≤‡∏ä‡∏µ‡∏û", 
                                      ["‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (Laborers)", "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å/‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà (Core staff)", "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ (Accountants)", "‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ (Managers)", "‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ (Drivers)", "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢ (Sales staff)", "‡πÑ‡∏≠‡∏ó‡∏µ (IT staff)", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"])
    org_type = st.sidebar.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£", ["‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß/‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• (Business Entity Type 3)", "‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏≠‡∏¥‡∏™‡∏£‡∏∞ (Self-employed)", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ (XNA)"])
    own_car = st.sidebar.checkbox("‡∏°‡∏µ‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß?")
    own_realty = st.sidebar.checkbox("‡∏°‡∏µ‡∏≠‡∏™‡∏±‡∏á‡∏´‡∏≤‡∏£‡∏¥‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå?", value=True)
    work_phone = st.sidebar.checkbox("‡∏°‡∏µ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô?", value=True)
    
    # 4. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï
    st.sidebar.subheader("4. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ")
    region_rating = st.sidebar.selectbox("‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (Region Rating)", [1, 2, 3], index=1, help="1=‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏°‡∏≤‡∏Å, 3=‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏ô‡πâ‡∏≠‡∏¢")
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (‡∏à‡∏≥‡∏•‡∏≠‡∏á)")
    st.sidebar.caption("‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ö‡∏π‡πÇ‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ 0.0 (‡πÅ‡∏¢‡πà) ‡∏ñ‡∏∂‡∏á 1.0 (‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°)")
    ext_source_1 = st.sidebar.slider("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà 1", 0.0, 1.0, 0.5)
    ext_source_2 = st.sidebar.slider("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà 2", 0.0, 1.0, 0.5)
    ext_source_3 = st.sidebar.slider("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà 3", 0.0, 1.0, 0.5)

    # --- Processing Inputs ---
    if st.button("üöÄ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Analyze Risk)", type="primary"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
            
            # Initialize input dict with MEDIANS for robustness
            # This ensures missing features (like previous application history) use average values instead of 0 (outlier)
            input_dict = {feat: medians.get(feat, 0) for feat in EXPECTED_FEATURES}
            
            # --- Map User Inputs to Features ---
            
            # Numeric Mappings
            input_dict['AMT_CREDIT'] = credit_amount
            input_dict['AMT_GOODS_PRICE'] = goods_price
            input_dict['DAYS_BIRTH'] = age * -365 # Convert to days (negative)
            input_dict['DAYS_EMPLOYED'] = employment_years * -365 # Convert to days (negative)
            input_dict['EXT_SOURCE_1'] = ext_source_1
            input_dict['EXT_SOURCE_2'] = ext_source_2
            input_dict['EXT_SOURCE_3'] = ext_source_3
            
            input_dict['REGION_RATING_CLIENT'] = region_rating
            input_dict['REGION_RATING_CLIENT_W_CITY'] = region_rating
            input_dict['FLAG_WORK_PHONE'] = 1 if work_phone else 0
            
            # Derived Domain Features (Replicating feature engineering)
            input_dict['CREDIT_TO_ANNUITY_RATIO'] = credit_amount / annuity if annuity > 0 else 0
            input_dict['CREDIT_TO_GOODS_RATIO'] = credit_amount / goods_price if goods_price > 0 else 0
            input_dict['AGE_YEARS'] = age
            input_dict['EMPLOYMENT_YEARS'] = employment_years
            input_dict['EMPLOYMENT_TO_AGE_RATIO'] = employment_years / age if age > 0 else 0
            
            ext_list = [ext_source_1, ext_source_2, ext_source_3]
            input_dict['EXT_SOURCE_MEAN'] = np.mean(ext_list)
            input_dict['EXT_SOURCE_STD'] = np.std(ext_list)
            input_dict['EXT_SOURCE_MIN'] = np.min(ext_list)
            input_dict['EXT_SOURCE_MAX'] = np.max(ext_list)

            # Categorical Mappings (One-Hot Encoding Manual Set)
            if '‡∏ä‡∏≤‡∏¢' in gender: input_dict['CODE_GENDER_M'] = 1
            if own_car: input_dict['FLAG_OWN_CAR_Y'] = 1
            
            if '‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤' in education: input_dict['NAME_EDUCATION_TYPE_Secondary / secondary special'] = 1
            elif '‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ' in education: input_dict['NAME_EDUCATION_TYPE_Higher education'] = 1
            
            if '‡πÅ‡∏ï‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß' in family_status: input_dict['NAME_FAMILY_STATUS_Married'] = 1
            elif '‡πÇ‡∏™‡∏î' in family_status: input_dict['NAME_FAMILY_STATUS_Single / not married'] = 1
            
            if '‡∏ö‡πâ‡∏≤‡∏ô/‡∏≠‡∏û‡∏≤‡∏£‡πå‡∏ó‡πÄ‡∏°‡∏ô‡∏ó‡πå‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß' in housing_type: input_dict['NAME_HOUSING_TYPE_House / apartment'] = 1
            elif '‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏û‡πà‡∏≠‡πÅ‡∏°‡πà' in housing_type: input_dict['NAME_HOUSING_TYPE_With parents'] = 1
            
            if '‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà' in occupation: input_dict['OCCUPATION_TYPE_Core staff'] = 1
            elif '‡∏Ñ‡∏ô‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ' in occupation: input_dict['OCCUPATION_TYPE_Drivers'] = 1
            elif '‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô' in occupation: input_dict['OCCUPATION_TYPE_Low-skill Laborers'] = 1
            
            if '‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß' in org_type: input_dict['ORGANIZATION_TYPE_Business Entity Type 3'] = 1
            elif '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏≠‡∏¥‡∏™‡∏£‡∏∞' in org_type: input_dict['ORGANIZATION_TYPE_Self-employed'] = 1
            elif '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏' in org_type: input_dict['ORGANIZATION_TYPE_XNA'] = 1
            
            # Income Type Mapping
            if '‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô' in income_type: input_dict['NAME_INCOME_TYPE_Working'] = 1
            elif '‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£' in income_type: input_dict['NAME_INCOME_TYPE_State servant'] = 1
            elif '‡∏ö‡∏≥‡∏ô‡∏≤‡∏ç' in income_type: input_dict['NAME_INCOME_TYPE_Pensioner'] = 1
            elif '‡πÄ‡∏≠‡∏Å‡∏ä‡∏ô' in income_type: input_dict['NAME_INCOME_TYPE_Commercial associate'] = 1

            # Convert to DataFrame
            try:
                # Force usage of EXPECTED_FEATURES (from CSV) to ensure exact match with training data.
                # Do NOT use model.feature_name_ as it may return sanitized names (underscores) 
                # which causes mismatch errors with Sklearn's validation.
                model_features = EXPECTED_FEATURES
                
                # Align input_dict keys with model features
                aligned_input = {feat: input_dict.get(feat, 0) for feat in model_features}
                
                df_predict = pd.DataFrame([aligned_input])
                
                # --- Preprocessing ---
                # 1. Impute
                if imputer:
                    df_predict_imputed = pd.DataFrame(imputer.transform(df_predict), columns=df_predict.columns)
                else:
                    df_predict_imputed = df_predict
                    
                # 2. Scale
                if scaler:
                    try:
                        # Ensure columns match scaler expectations (order matters)
                        # The scaler was fitted on 'expected_features', which matches 'model_features' (ideally)
                        df_predict_scaled = pd.DataFrame(scaler.transform(df_predict_imputed), columns=df_predict.columns)
                    except ValueError as ve:
                        # Only warn in console, attempt to predict anyway if robust
                        print(f"Scaling warning: {ve}") 
                        df_predict_scaled = df_predict_imputed
                else:
                    df_predict_scaled = df_predict_imputed
                
                # --- Prediction ---
                probability = model.predict_proba(df_predict_scaled)[:, 1][0]
                
                # --- Display ---
                # Credit Score Simulation (e.g., 300-850 scale inverse to risk)
                credit_score = int(850 - (probability * 550))
                
                st.write("---")
                st.subheader("üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(label="‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏´‡∏ô‡∏µ‡πâ (Default Prob.)", value=f"{probability:.2%}")
                
                with col2:
                    st.metric(label="‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏™‡∏Å‡∏≠‡∏£‡πå (Credit Score)", value=f"{credit_score}")
                    
                with col3:
                    if probability < 0.2:
                        st.balloons()
                        st.success("**‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥ (Low Risk)**\n\n‚úÖ ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô")
                    elif probability < 0.5:
                        st.warning("**‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á (Medium Risk)**\n\n‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
                    else:
                        st.error("**‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á (High Risk)**\n\n‚ùå ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô")

                # Factors
                st.write("")
                with st.expander("‡∏î‡∏π‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (Analysis Details)"):
                    st.write("‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:")
                    key_metrics = {
                        "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Ext Source Mean)": input_dict['EXT_SOURCE_MEAN'],
                        "‡∏≠‡∏≤‡∏¢‡∏∏‡∏á‡∏≤‡∏ô (‡∏õ‡∏µ)": employment_years,
                        "‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ": input_dict['CREDIT_TO_ANNUITY_RATIO']
                    }
                    st.bar_chart(pd.DataFrame.from_dict(key_metrics, orient='index', columns=['Value']))

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {str(e)}")
                st.write("‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô")


if __name__ == "__main__":
    main()
